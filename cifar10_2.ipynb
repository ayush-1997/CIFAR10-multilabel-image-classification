{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOu5Ge__66kj"
   },
   "source": [
    "**Importing necessary libraries** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6amQA-gUGoBj"
   },
   "source": [
    "**Notebook Summary**\n",
    "Problem: Object Recognition model for CIFAR10\n",
    "Environment: Jupyter,Keras\n",
    "\n",
    "Input: CIFAR10 dataset containing 10 classes of images with shape(32,32,3)\n",
    "Output: CNN multilabel classification model with 86.57% validation accuracy\n",
    "\n",
    "**Model architecture:** \n",
    "Total layers: 17\n",
    "Types of layers: Conv2d,Batch Normalization,MaxPool and Dropout(regularization)\n",
    "Total Epochs: 170\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "3ESGfpCeVgHU",
    "outputId": "73191bce-6c14-4a10-f4b8-c9c7299ac8a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# import backend\n",
    "import tensorflow as  tf\n",
    "\n",
    "# Model architecture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "from keras.layers import MaxPool2D, Activation, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Annealer\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Data processing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Progressor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLnjZVM_VgHe"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Gl5_qXrkVgHj",
    "outputId": "e18f7e87-f953-4e7a-fd8b-d409d9078f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETo6ku7gVgHp"
   },
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "y_train =to_categorical(y_train, num_classes)\n",
    "y_test =to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "A86Ty_1GVgHv",
    "outputId": "40e16458-2431-4ae2-ec51-d53e10107b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkHfmFPGVgH2"
   },
   "outputs": [],
   "source": [
    "# Function to reshape and scaling image\n",
    "def Scale_Reshape(x):\n",
    "    x_min = x.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = x.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    x = (x - x_min)/(x_max-x_min)\n",
    "    \n",
    "    x = x.reshape(-1, 32, 32, 3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbrQBjfeVgH-"
   },
   "outputs": [],
   "source": [
    "# Training data processing\n",
    "x_train = Scale_Reshape(x_train)\n",
    "\n",
    "# Test data processing\n",
    "x_test = Scale_Reshape(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QobtZGFIVgIN"
   },
   "outputs": [],
   "source": [
    "##17 layered network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,  kernel_size = 3,kernel_initializer='he_normal', activation='relu', input_shape = (32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size = 3, kernel_initializer='he_normal', strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, kernel_size = 3, strides=1, kernel_initializer='he_normal' ,padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, kernel_size = 3,kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_initializer='he_normal', activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, kernel_initializer='glorot_uniform', activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "3DpRgaN_VgIg",
    "outputId": "873a08f1-fd96-4927-adba-e1d13642bc7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 304,906\n",
      "Trainable params: 304,330\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEGGZONaVgIs"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0,  \n",
    "        zoom_range = 0.0,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "# data generator model to train and validation set\n",
    "batch_size_1 = 32\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=batch_size_1)\n",
    "val_gen = datagen.flow(x_test, y_test, batch_size=batch_size_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "ES5UkDvgfyo1",
    "outputId": "bd826f1d-bdb2-4374-de70-f05735a9ffae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 44s 28ms/step - loss: 1.5471 - acc: 0.4575 - val_loss: 1.2712 - val_acc: 0.5483\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 1.1432 - acc: 0.6001 - val_loss: 1.0439 - val_acc: 0.6296\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.9919 - acc: 0.6537 - val_loss: 0.9102 - val_acc: 0.6794\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.9060 - acc: 0.6869 - val_loss: 0.9225 - val_acc: 0.6794\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.8361 - acc: 0.7114 - val_loss: 0.7732 - val_acc: 0.7293\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.7892 - acc: 0.7293 - val_loss: 0.8013 - val_acc: 0.7323\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.7469 - acc: 0.7438 - val_loss: 0.7168 - val_acc: 0.7517\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.7160 - acc: 0.7533 - val_loss: 0.7248 - val_acc: 0.7524\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.6824 - acc: 0.7664 - val_loss: 0.6898 - val_acc: 0.7639\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.6645 - acc: 0.7712 - val_loss: 0.7064 - val_acc: 0.7620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "ojCxQ_Se9nSa",
    "outputId": "df7be91a-97b6-4cdd-8a6d-12a9c77aca51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.6356 - acc: 0.7805 - val_loss: 0.6945 - val_acc: 0.7677\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.6227 - acc: 0.7873 - val_loss: 0.7172 - val_acc: 0.7545\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.6042 - acc: 0.7904 - val_loss: 0.6472 - val_acc: 0.7833\n",
      "Epoch 4/10\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5957 - acc: 0.7959Epoch 5/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5821 - acc: 0.8001 - val_loss: 0.6598 - val_acc: 0.7758\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.5699 - acc: 0.8031 - val_loss: 0.6002 - val_acc: 0.7929\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.5566 - acc: 0.8076 - val_loss: 0.5953 - val_acc: 0.8001\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.5504 - acc: 0.8109 - val_loss: 0.6156 - val_acc: 0.7870\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5327 - acc: 0.8158 - val_loss: 0.6241 - val_acc: 0.7867\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5295 - acc: 0.8185 - val_loss: 0.7464 - val_acc: 0.7630\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "KE7KAy6Q_EEl",
    "outputId": "935c8f25-ab0e-4bb5-b599-53cdf161336d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5209 - acc: 0.8198 - val_loss: 0.5463 - val_acc: 0.8136\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5208 - acc: 0.8199 - val_loss: 0.5727 - val_acc: 0.8114\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.5078 - acc: 0.8260 - val_loss: 0.5652 - val_acc: 0.8101\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.4960 - acc: 0.8295 - val_loss: 0.5636 - val_acc: 0.8118\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.4872 - acc: 0.8325 - val_loss: 0.7558 - val_acc: 0.7655\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4827 - acc: 0.8354 - val_loss: 0.6182 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4814 - acc: 0.8345 - val_loss: 0.5733 - val_acc: 0.8099\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.4731 - acc: 0.8362 - val_loss: 0.5859 - val_acc: 0.8002\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4701 - acc: 0.8388 - val_loss: 0.5581 - val_acc: 0.8123\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.4620 - acc: 0.8436 - val_loss: 0.5481 - val_acc: 0.8131\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "U4isVi2AAd3u",
    "outputId": "df4f3332-0602-4943-9f37-300b2bb6fbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4571 - acc: 0.8437 - val_loss: 0.5576 - val_acc: 0.8127\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4505 - acc: 0.8439 - val_loss: 0.5387 - val_acc: 0.8178\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4511 - acc: 0.8444 - val_loss: 0.5600 - val_acc: 0.8120\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4525 - acc: 0.8429 - val_loss: 0.5879 - val_acc: 0.8029\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4429 - acc: 0.8487 - val_loss: 0.5790 - val_acc: 0.8095\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4373 - acc: 0.8480 - val_loss: 0.5652 - val_acc: 0.8103\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4302 - acc: 0.8546 - val_loss: 0.5839 - val_acc: 0.8102\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4277 - acc: 0.8530 - val_loss: 0.5471 - val_acc: 0.8153\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4252 - acc: 0.8549 - val_loss: 0.5299 - val_acc: 0.8267\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4222 - acc: 0.8540 - val_loss: 0.5470 - val_acc: 0.8115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "lclgDrspB7Bw",
    "outputId": "bcc40df2-d96b-4280-fc92-2a8c0ed2135f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4146 - acc: 0.8574 - val_loss: 0.6129 - val_acc: 0.8047\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4222 - acc: 0.8540 - val_loss: 0.5287 - val_acc: 0.8264\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4106 - acc: 0.8576 - val_loss: 0.5356 - val_acc: 0.8212\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4110 - acc: 0.8579 - val_loss: 0.5252 - val_acc: 0.8224\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.4010 - acc: 0.8622 - val_loss: 0.5773 - val_acc: 0.8104\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3974 - acc: 0.8632 - val_loss: 0.6140 - val_acc: 0.8055\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.4027 - acc: 0.8620 - val_loss: 0.5129 - val_acc: 0.8269\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3970 - acc: 0.8619 - val_loss: 0.5569 - val_acc: 0.8171\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3912 - acc: 0.8657 - val_loss: 0.5189 - val_acc: 0.8256\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.3855 - acc: 0.8674 - val_loss: 0.5656 - val_acc: 0.8212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8DoNgN2yDViw",
    "outputId": "7ecbb2f9-3c08-4343-ee62-6e7311165d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3813 - acc: 0.8684 - val_loss: 0.5396 - val_acc: 0.8222\n",
      "Epoch 2/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3861 - acc: 0.8659 - val_loss: 0.5325 - val_acc: 0.8186\n",
      "Epoch 3/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3852 - acc: 0.8666 - val_loss: 0.5569 - val_acc: 0.8225\n",
      "Epoch 4/30\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.3856 - acc: 0.8671 - val_loss: 0.5699 - val_acc: 0.8176\n",
      "Epoch 5/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3744 - acc: 0.8699 - val_loss: 0.5387 - val_acc: 0.8246\n",
      "Epoch 6/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3756 - acc: 0.8699 - val_loss: 0.5200 - val_acc: 0.8316\n",
      "Epoch 7/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3731 - acc: 0.8721 - val_loss: 0.5073 - val_acc: 0.8326\n",
      "Epoch 8/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3701 - acc: 0.8715 - val_loss: 0.5370 - val_acc: 0.8241\n",
      "Epoch 9/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3671 - acc: 0.8731 - val_loss: 0.5570 - val_acc: 0.8240\n",
      "Epoch 10/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3672 - acc: 0.8738 - val_loss: 0.5081 - val_acc: 0.8341\n",
      "Epoch 11/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3639 - acc: 0.8740 - val_loss: 0.5379 - val_acc: 0.8293\n",
      "Epoch 12/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3663 - acc: 0.8726 - val_loss: 0.5282 - val_acc: 0.8308\n",
      "Epoch 13/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3658 - acc: 0.8734 - val_loss: 0.5580 - val_acc: 0.8219\n",
      "Epoch 14/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3581 - acc: 0.8736 - val_loss: 0.5262 - val_acc: 0.8270\n",
      "Epoch 15/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3590 - acc: 0.8755 - val_loss: 0.5175 - val_acc: 0.8292\n",
      "Epoch 16/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3538 - acc: 0.8788 - val_loss: 0.5232 - val_acc: 0.8308\n",
      "Epoch 17/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3585 - acc: 0.8766 - val_loss: 0.5255 - val_acc: 0.8328\n",
      "Epoch 18/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3518 - acc: 0.8788 - val_loss: 0.5096 - val_acc: 0.8346\n",
      "Epoch 19/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3497 - acc: 0.8773 - val_loss: 0.5286 - val_acc: 0.8277\n",
      "Epoch 20/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3471 - acc: 0.8791 - val_loss: 0.5349 - val_acc: 0.8279\n",
      "Epoch 21/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3470 - acc: 0.8803 - val_loss: 0.5436 - val_acc: 0.8293\n",
      "Epoch 22/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3442 - acc: 0.8801 - val_loss: 0.4770 - val_acc: 0.8463\n",
      "Epoch 23/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3487 - acc: 0.8786 - val_loss: 0.5126 - val_acc: 0.8309\n",
      "Epoch 24/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3408 - acc: 0.8826 - val_loss: 0.4961 - val_acc: 0.8333\n",
      "Epoch 25/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3413 - acc: 0.8832 - val_loss: 0.5815 - val_acc: 0.8173\n",
      "Epoch 26/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3391 - acc: 0.8823 - val_loss: 0.5325 - val_acc: 0.8351\n",
      "Epoch 27/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3351 - acc: 0.8841 - val_loss: 0.5601 - val_acc: 0.8260\n",
      "Epoch 28/30\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.3311 - acc: 0.8856 - val_loss: 0.5180 - val_acc: 0.8379\n",
      "Epoch 29/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3409 - acc: 0.8840 - val_loss: 0.5243 - val_acc: 0.8319\n",
      "Epoch 30/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3310 - acc: 0.8860 - val_loss: 0.5103 - val_acc: 0.8344\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 30, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "A-mJfkgRHbI1",
    "outputId": "52d5271e-e695-4353-f2a4-dca72aabbd3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3365 - acc: 0.8842 - val_loss: 0.5085 - val_acc: 0.8390\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3344 - acc: 0.8849 - val_loss: 0.5350 - val_acc: 0.8358\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3255 - acc: 0.8877 - val_loss: 0.4923 - val_acc: 0.8425\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3300 - acc: 0.8864 - val_loss: 0.5334 - val_acc: 0.8354\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3252 - acc: 0.8874 - val_loss: 0.5536 - val_acc: 0.8194\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3206 - acc: 0.8884 - val_loss: 0.5168 - val_acc: 0.8378\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.3284 - acc: 0.8864 - val_loss: 0.5010 - val_acc: 0.8379\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.3201 - acc: 0.8901 - val_loss: 0.5164 - val_acc: 0.8342\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3198 - acc: 0.8904 - val_loss: 0.5181 - val_acc: 0.8355\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 38s 25ms/step - loss: 0.3156 - acc: 0.8905 - val_loss: 0.5096 - val_acc: 0.8334\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tyt285gdJiVR",
    "outputId": "d9cc5ffb-8e33-4748-f74b-bd06efd847e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3209 - acc: 0.8901 - val_loss: 0.4989 - val_acc: 0.8396\n",
      "Epoch 2/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3175 - acc: 0.8897 - val_loss: 0.5194 - val_acc: 0.8344\n",
      "Epoch 3/30\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.3169 - acc: 0.8910 - val_loss: 0.5193 - val_acc: 0.8356\n",
      "Epoch 4/30\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.3113 - acc: 0.8920 - val_loss: 0.5191 - val_acc: 0.8404\n",
      "Epoch 5/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3139 - acc: 0.8920 - val_loss: 0.5575 - val_acc: 0.8235\n",
      "Epoch 6/30\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.3122 - acc: 0.8921 - val_loss: 0.5489 - val_acc: 0.8278\n",
      "Epoch 7/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3140 - acc: 0.8921 - val_loss: 0.5278 - val_acc: 0.8368\n",
      "Epoch 8/30\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.3093 - acc: 0.8930 - val_loss: 0.5016 - val_acc: 0.8374\n",
      "Epoch 9/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3080 - acc: 0.8935 - val_loss: 0.4967 - val_acc: 0.8441\n",
      "Epoch 10/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3077 - acc: 0.8943 - val_loss: 0.5270 - val_acc: 0.8350\n",
      "Epoch 11/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3018 - acc: 0.8939 - val_loss: 0.5200 - val_acc: 0.8395\n",
      "Epoch 12/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3050 - acc: 0.8948 - val_loss: 0.4952 - val_acc: 0.8381\n",
      "Epoch 13/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3002 - acc: 0.8961 - val_loss: 0.5090 - val_acc: 0.8452\n",
      "Epoch 14/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2999 - acc: 0.8961 - val_loss: 0.5106 - val_acc: 0.8391\n",
      "Epoch 15/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3064 - acc: 0.8939 - val_loss: 0.4874 - val_acc: 0.8486\n",
      "Epoch 16/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3017 - acc: 0.8962 - val_loss: 0.5041 - val_acc: 0.8475\n",
      "Epoch 17/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3012 - acc: 0.8961 - val_loss: 0.4860 - val_acc: 0.8427\n",
      "Epoch 18/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3015 - acc: 0.8947 - val_loss: 0.5433 - val_acc: 0.8290\n",
      "Epoch 19/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.3031 - acc: 0.8970 - val_loss: 0.4986 - val_acc: 0.8448\n",
      "Epoch 20/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2946 - acc: 0.8989 - val_loss: 0.5146 - val_acc: 0.8365\n",
      "Epoch 21/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2994 - acc: 0.8976 - val_loss: 0.5318 - val_acc: 0.8427\n",
      "Epoch 22/30\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.2948 - acc: 0.8988 - val_loss: 0.5445 - val_acc: 0.8317\n",
      "Epoch 23/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2965 - acc: 0.8970 - val_loss: 0.4792 - val_acc: 0.8488\n",
      "Epoch 24/30\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.2966 - acc: 0.8976 - val_loss: 0.5347 - val_acc: 0.8339\n",
      "Epoch 25/30\n",
      "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2980 - acc: 0.8987 - val_loss: 0.5033 - val_acc: 0.8429\n",
      "Epoch 26/30\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2939 - acc: 0.8998 - val_loss: 0.5108 - val_acc: 0.8382\n",
      "Epoch 27/30\n",
      "1562/1562 [==============================] - 37s 23ms/step - loss: 0.2998 - acc: 0.8986 - val_loss: 0.5311 - val_acc: 0.8367\n",
      "Epoch 28/30\n",
      "1562/1562 [==============================] - 37s 23ms/step - loss: 0.2931 - acc: 0.8986 - val_loss: 0.5080 - val_acc: 0.8409\n",
      "Epoch 29/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2911 - acc: 0.8985 - val_loss: 0.5526 - val_acc: 0.8313\n",
      "Epoch 30/30\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2906 - acc: 0.8999 - val_loss: 0.5497 - val_acc: 0.8340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 30, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "LX1dYblwOiiF",
    "outputId": "47cdaf0e-8f15-4b52-9775-9e7085c3600b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.2878 - acc: 0.9000 - val_loss: 0.5004 - val_acc: 0.8420\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2903 - acc: 0.9002 - val_loss: 0.5062 - val_acc: 0.8354\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 0.2882 - acc: 0.9009 - val_loss: 0.5018 - val_acc: 0.8463\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2882 - acc: 0.9016 - val_loss: 0.5073 - val_acc: 0.8408\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.2846 - acc: 0.9024 - val_loss: 0.5215 - val_acc: 0.8409\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2886 - acc: 0.9012 - val_loss: 0.5385 - val_acc: 0.8352\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2915 - acc: 0.9000 - val_loss: 0.5087 - val_acc: 0.8392\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2844 - acc: 0.9031 - val_loss: 0.5617 - val_acc: 0.8296\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2822 - acc: 0.9044 - val_loss: 0.5252 - val_acc: 0.8353\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2895 - acc: 0.8994 - val_loss: 0.4856 - val_acc: 0.8515\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tVZhjsODP_F4",
    "outputId": "a5fc5958-01fb-4314-ed46-ad60bce29b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.2847 - acc: 0.9023 - val_loss: 0.4929 - val_acc: 0.8480\n",
      "Epoch 2/30\n",
      "1562/1562 [==============================] - 35s 22ms/step - loss: 0.2849 - acc: 0.9013 - val_loss: 0.5415 - val_acc: 0.8374\n",
      "Epoch 3/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2833 - acc: 0.9029 - val_loss: 0.5365 - val_acc: 0.8323\n",
      "Epoch 4/30\n",
      "1562/1562 [==============================] - 35s 23ms/step - loss: 0.2861 - acc: 0.9033 - val_loss: 0.4859 - val_acc: 0.8490\n",
      "Epoch 5/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2833 - acc: 0.9025 - val_loss: 0.5526 - val_acc: 0.8353\n",
      "Epoch 6/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2780 - acc: 0.9038 - val_loss: 0.5498 - val_acc: 0.8383\n",
      "Epoch 7/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2832 - acc: 0.9025 - val_loss: 0.5205 - val_acc: 0.8369\n",
      "Epoch 8/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2782 - acc: 0.9039 - val_loss: 0.4949 - val_acc: 0.8475\n",
      "Epoch 9/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2837 - acc: 0.9020 - val_loss: 0.4975 - val_acc: 0.8495\n",
      "Epoch 10/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2769 - acc: 0.9051 - val_loss: 0.5409 - val_acc: 0.8411\n",
      "Epoch 11/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2723 - acc: 0.9066 - val_loss: 0.5381 - val_acc: 0.8374\n",
      "Epoch 12/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2793 - acc: 0.9041 - val_loss: 0.5426 - val_acc: 0.8347\n",
      "Epoch 13/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2769 - acc: 0.9042 - val_loss: 0.4980 - val_acc: 0.8480\n",
      "Epoch 14/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2768 - acc: 0.9058 - val_loss: 0.5274 - val_acc: 0.8409\n",
      "Epoch 15/30\n",
      "1562/1562 [==============================] - 34s 21ms/step - loss: 0.2736 - acc: 0.9052 - val_loss: 0.5322 - val_acc: 0.8340\n",
      "Epoch 16/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2784 - acc: 0.9044 - val_loss: 0.5030 - val_acc: 0.8437\n",
      "Epoch 17/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2760 - acc: 0.9056 - val_loss: 0.5260 - val_acc: 0.8378\n",
      "Epoch 18/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2737 - acc: 0.9059 - val_loss: 0.5152 - val_acc: 0.8399\n",
      "Epoch 19/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2758 - acc: 0.9059 - val_loss: 0.5225 - val_acc: 0.8335\n",
      "Epoch 20/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2695 - acc: 0.9083 - val_loss: 0.5069 - val_acc: 0.8389\n",
      "Epoch 21/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2719 - acc: 0.9048 - val_loss: 0.5469 - val_acc: 0.8361\n",
      "Epoch 22/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2652 - acc: 0.9085 - val_loss: 0.5424 - val_acc: 0.8416\n",
      "Epoch 23/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2704 - acc: 0.9071 - val_loss: 0.4976 - val_acc: 0.8442\n",
      "Epoch 24/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2778 - acc: 0.9045 - val_loss: 0.5300 - val_acc: 0.8420\n",
      "Epoch 25/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2677 - acc: 0.9089 - val_loss: 0.5139 - val_acc: 0.8463\n",
      "Epoch 26/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2720 - acc: 0.9071 - val_loss: 0.4940 - val_acc: 0.8474\n",
      "Epoch 27/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2720 - acc: 0.9077 - val_loss: 0.5039 - val_acc: 0.8403\n",
      "Epoch 28/30\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2682 - acc: 0.9071 - val_loss: 0.5120 - val_acc: 0.8439\n",
      "Epoch 29/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2709 - acc: 0.9067 - val_loss: 0.5170 - val_acc: 0.8407\n",
      "Epoch 30/30\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2674 - acc: 0.9082 - val_loss: 0.5340 - val_acc: 0.8382\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 30, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "wujO0JWKT_d_",
    "outputId": "7e689626-d2c3-4927-a771-cc343269ebf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2680 - acc: 0.9076 - val_loss: 0.5281 - val_acc: 0.8424\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2650 - acc: 0.9099 - val_loss: 0.5415 - val_acc: 0.8497\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2632 - acc: 0.9106 - val_loss: 0.5074 - val_acc: 0.8479\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2666 - acc: 0.9076 - val_loss: 0.4859 - val_acc: 0.8474\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2631 - acc: 0.9090 - val_loss: 0.4963 - val_acc: 0.8467\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2613 - acc: 0.9100 - val_loss: 0.5285 - val_acc: 0.8452\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.2654 - acc: 0.9087 - val_loss: 0.4996 - val_acc: 0.8475\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2600 - acc: 0.9101 - val_loss: 0.5260 - val_acc: 0.8448\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2605 - acc: 0.9100 - val_loss: 0.5036 - val_acc: 0.8447\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 33s 21ms/step - loss: 0.2691 - acc: 0.9076 - val_loss: 0.5387 - val_acc: 0.8329\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_1,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "3zN4V-qSVrSl",
    "outputId": "00d86e9a-bc68-4227-8983-1ffbd7364e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2552 - acc: 0.9104 - val_loss: 0.5150 - val_acc: 0.8476\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2688 - acc: 0.9073 - val_loss: 0.5174 - val_acc: 0.8450\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 0.2508 - acc: 0.9129 - val_loss: 0.5193 - val_acc: 0.8485\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2614 - acc: 0.9084 - val_loss: 0.5049 - val_acc: 0.8472\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 0.2616 - acc: 0.9122 - val_loss: 0.5392 - val_acc: 0.8467\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2673 - acc: 0.9108 - val_loss: 0.5709 - val_acc: 0.8333\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 0.2543 - acc: 0.9128 - val_loss: 0.5308 - val_acc: 0.8459\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2664 - acc: 0.9077 - val_loss: 0.4834 - val_acc: 0.8450\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 0.2554 - acc: 0.9113 - val_loss: 0.4822 - val_acc: 0.8505\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 16s 21ms/step - loss: 0.2593 - acc: 0.9114 - val_loss: 0.5344 - val_acc: 0.8472\n"
     ]
    }
   ],
   "source": [
    "batch_size_2=64\n",
    "history = model.fit_generator(train_gen, \n",
    "                              epochs = 10, \n",
    "                              steps_per_epoch = x_train.shape[0] // batch_size_2,\n",
    "                              validation_data = val_gen,\n",
    "                              validation_steps = x_test.shape[0] // batch_size_2,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0qXsg_W5VgJM",
    "outputId": "6afde9a2-70eb-4fa1-d381-d9f5dca1f80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 120us/step\n",
      "Final loss: 0.4705, final accuracy: 0.8657\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "EBR0AbRCVgJV",
    "outputId": "9f793408-b591-4b68-d35b-38facd4ad269"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEvCAYAAAAwx8gYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU5dn/8c9FQoAECEFQZClbEcgK\nISyyL4LgjoKIoEJV1J+CVmlFaytiba1VirXU1qpULYo8+liXsjxVcatWSFiCYReCQFDCFgJhyZDr\n98edSSYhwCSZMEnmer9e5zUzZ86cc59ZvnOf+5xzH1FVjDEmlNUJdgGMMSbYLAiNMSHPgtAYE/Is\nCI0xIc+C0BgT8iwIjTEhLzzYBSitWbNm2q5du2AXwxhTy6Slpe1V1eZlPVftgrBdu3akpqYGuxjG\nmFpGRLaf7jnbNDbGhDwLQmNMyLMgNKEnLw/y84NdClONWBCa0KAKn38ON90E550HbdvCH/8IR48G\nu2SmGrAgNLVbdjY88wzExsLAgfDee3DLLdC5M9x7L3TsaIFoLAhNLVRQAB99BOPGQatWMH06xMTA\nvHmQlQV/+QssW+YGC0SDBaGpTXbvht/+Fjp1gksugX//G/7f/4O1a+HLL2HSJIiKKp5+8GALRANY\nEJqa7uRJWLQIRo+GNm3g4Yfd7fz5rvY3Zw7Ex595HmUFYocO8OyzFoghwoLQ1Ew7dsBjj0H79nD5\n5fCf/8D998PGjfDJJ3DjjVC/fvnm6RuIXbrAffdZIIYIC0JTc+Tnwz//6YKvXTuYORO6doX/+R/Y\nuROeegouuqjyy7FADDkWhKb627YNfvELd8jL6NGwahU89BBs3QpLl8KYMRAREfjlWiCGDAtCUz2d\nOOFqesOHu/B58kno0QPefRe++w5+/Wu3WXwueAPxk09cDdQCsdaxIDTVy6ZN8LOfQevWcP317vFj\nj8H27fD++3DVVRAepL5CBg2Cjz+2QKyFLAhN8B075vbyDhrk9trOmQMDBsDixW7z91e/csFYXVgg\n1joWhCZ4tm+HBx90Bz1PnAi7drnjAHfsgLffhpEjISws2KU8PQvEWsOC0Jxbqq69bfRoFxrPPAND\nhrgzQTZtghkzoEWLYJeyfCwQzy1VeOUVyMkJ2CwtCM25ceQI/PWvkJgIQ4e6DhAefNDtEX7rLTeu\nTg3/OlogVr1vv4Vhw9xZQi+9FLDZ1vBvnqn2tm1z5/q2bg133gl168LLL7vN39/8xp0FUtuUFYid\nOsGCBa42Y8rv5EmYPRsSEiAtzf2p3ndfwGZvQWgCTxU+/NDt4e3Y0e38uPRS+OIL9yWePBkaNAh2\nKauebyBecAGMH++aAdLTg12ymuWbb6BvX3jgAVcbzMiAKVMCugVhQWgC5/Bh+POfIS7OHf/33/+6\nA6G3b3e1oX79QCTYpTz3Bg2C5ctdLeabb6B7d5g6FQ4cCHbJqrcTJ9yhU8nJ7uiB11933ahVxREE\nqlqthh49eqjxUVCgevJksEtxZps3q953n2p0tCqopqSovvKK6tGjwS5Z9bNvn+rdd6vWqaParJnq\nCy+oejzBLlX1s3y5any8+z7deKPqnj2VniWQqqfJHdFq1maRkpKi5/wqdh6PO5bt2DE4frzsW9/7\nJ06cmyE/392Gh7vj6xITSw6tWgWvhlVQ4Lq5eu451/tLWJg7AHrqVOjdOzRrfuWxZo17rz7/3J0x\n86c/QZ8+wS5V8OXlueNG//AHuPBCeP55uPLKgMxaRNJUNaXM52p8EP7tb+6wi9OF1pkCzXtbUBC4\nFahXz533Gsjh+HHXLpKe7jYzvWJiTg3HuLiSfe4FWm6uO3Thuefc+37BBW4nyB13uC+u8Z+qazKY\nPt11GXbLLe5Uwpp2+FCgfPIJ3Hab2zN8xx3wu99BdHTAZl+7g3D4cNfpZr16rtul0rdljavscxER\nZQdeWFjV14QOHnTtTOnpxcPata59DtzyO3Y8NSDbt69c4/KmTa7W8ve/uzDs3dvVaMaOrZoOD0LJ\n4cPwxBPumMr69V2vOlOnuj3soSAnB37+c3jhBffd/dvf3E6lAKvdQWhcjTYzszgUvQG5eXPx4RpR\nUe7QA99wTEiAJk3OPN8lS1ztb8kS98McN879SHv1OierFlI2b3aHhCxa5A67efZZ90dfm33wgdui\n2L3b9Sf52GMQGVklizpTEFZqxwYwEtgIbAFmlPH8JCAbWF043Ha2edrOkgA6fNg1Or/4ouq0aaqD\nB6vGxLgGaO/Qpo3q5ZerPvSQ6htvqGZkqO7dqzpnjuqPf+ymufBC1VmzVL//PthrFBref1+1Y0f3\n3o8erbptW7BLFHh79qiOH+/WMT5e9euvq3yRnGFnSWVCMAz4FugARABrgNhS00wC/lSe+VoQVrGC\nAtWdO1UXLVJ98km3Ry4+XjU8vGRAgmrfvi4cjx8PdqlDz9Gjqk88oRoZqVq/vuqjj6rm5QW7VJVX\nUOC+U82aqdatq/rYY+fs+3WmIKxMf0a9gC2qurWw2rkAuBpYV4l5mqom4vY2t2oFo0YVjz9+HDZs\ncJvW27bBZZe5vZkmOOrXd9dfuekm1y3ZY4+59tnZs9152jVxr/yuXXDXXa47tV693ClyZ7uezDlS\nmQOqWwE7fB7vLBxX2nUiki4ib4lImedTicgUEUkVkdTs7OxKFMlUWL16kJTkeoH55S8tBKuLNm3c\nnuVly6BxY7juOhgxAtavD3bJ/KfqdoDExrozjmbPdjs4q0kIQtWfWfI+0E5VE4F/A6+UNZGqvqCq\nKaqa0rx58youkjE10ODBsHKlu9Roaqrb2fXAA3DoULBLdmbeThKmTHF/rmvXwk9/Wu26V6tMEO4C\nfGt4rQvHFVHVfap6vPDhi4BVM4ypqPBwt8d+0ybX+8of/uAuVvXKK4E9FjYQSneS8Le/ua7WOnYM\ndsnKVJkgXAF0EpH2IhIB3AC85zuBiPgeYXsVUIPq88ZUU82bu2BZvtxdzW/SJOjf3wVOdeDbScIl\nl8C6de5A6WrcrlnhIFRVD3APsBQXcAtVNUNEZonIVYWTTRORDBFZA0zD7UU2xgRCSopra5s3z22C\n9uzpNkH37g1OeXw7Sdi2zbVtvvuu2zFXzdkB1cbUBjk5MGuWa0Ns2NAdmN28uducDgtzt/7er8hr\n0tPh9ttdbXDCBNf1WrNmwX5XSrAzS4wJFevXw7Rpbu/suda6NfzlL3D55ed+2X44UxAG6bqIxpgq\n0bWr6xXowAHXe5HH43ZceDxVe79+fddpROPGwX4HKsSC0JjaKCYm2CWoUayHamNMyLMgNMaEPAtC\nY0zIsyA0xoQ8C0JjTMizIDTGhDw7fMYYP5w4cYJvv/2WvLy8YBfFnEVkZCQdO3YkohzX0rEgNMYP\n3377LU2aNKFz587UqcxFsEyVKigo4IcffmDTpk107tyZun5eAMs+UWP8kJeXxwUXXGAhWM3VqVOH\nCy64gGPHjvH6669z2Ht1x7O9rorLZUytYSFYM9SpUwcR4dChQ3z++ef+vaaKy2SMCYB9+/bRrVs3\nunXrRosWLWjVqlXR4xMnTvg1j8mTJ7Nx48YzTjN37lzmz58fiCLTv39/Vq9eHZB5VURkZCT79+/3\na1prIzSmBjjvvPOKQmXmzJk0bNiQ6dOnl5jGe0W209Vc582bd9bl3H333ZUvbDUhIvjbu5bVCI2p\nwbZs2UJsbCwTJkwgLi6O3bt3M2XKFFJSUoiLi2PWrFlF03praB6PhyZNmjBjxgySkpK4+OKL2bNn\nDwCPPPIIc+bMKZp+xowZ9OrVi86dO/Pll18CcOTIEa677jpiY2MZM2YMKSkpZ635/eMf/yAhIYH4\n+HgefvhhADweDzfddFPR+D/+8Y8A/OEPfyA2NpbExEQmTpwY8PesLFYjNKaG27BhA6+++iopKa6r\nvSeffJKmTZvi8XgYMmQIY8aMITY2tsRrcnJyGDRoEE8++ST3338/L7/8MjNmzDhl3qrK8uXLee+9\n95g1axZLlizhueeeo0WLFrz99tusWbOG5OTkM5Zv586dPPLII6SmphIdHc0ll1zCBx98QPPmzdm7\ndy9r164F4ODBgwA89dRTbN++nYiIiKJxVc2C0Jhyuu8+CHTTV7durlPniujYsWNRCAK88cYbvPTS\nS3g8HrKysli3bt0pQdigQQNGFV7XukePHqfdqXDttdcWTZOZmQnAF198wYMPPghAUlIScXFxZyzf\n119/zdChQ2lW2GP1jTfeyGeffcaDDz7Ixo0bmTZtGpdffjkjRowAIC4ujokTJ3L11VdzzTXXlPPd\nqBjbNDamhouKiiq6v3nzZp599lk+/vhj0tPTGTlyJMeOHTvlNb4HG4eFheHxeMqcd7169c46TUWd\nd955pKenM2DAAObOncsdd9wBwNKlS7nzzjtZsWIFvXr14uTJkwFdblmsRmhMOVW05nYuHDp0iEaN\nGtG4cWN2797N0qVLGTlyZECX0a9fPxYuXMiAAQNYu3Yt69atO+P0vXv3Zvr06ezbt4/o6GgWLFjA\n9OnTyc7Opn79+owdO5ZOnTpx2223cfLkSXbu3MnQoUPp378/bdq0IS8vj0aNGgV0HUqzIDSmFklO\nTiY2NpYuXbrQtm1b+vXrF/BlTJ06lZtvvpnY2NiiITo6+rTTt27dmscff5zBgwejqlx55ZVcfvnl\nrFy5kltvvRVVRUT43e9+h8fj4cYbbyQ3N5eCggKmT59e5SEIdvEmY/ySlpZGjx49gl2MasHj8eDx\neKhfvz6bN29mxIgRbN68mfDw6lOvSktLY82aNURERBTtebaLNxljAubw4cMMGzYMj8eDqvLXv/61\nWoVgRdTs0htjzrkmTZqQlpYW7GIElO01NsaEPAtCY0zIq1QQishIEdkoIltE5NTD0ounu05EVETK\nbKg0xphgqnAQikgYMBcYBcQC40UktozpGgH3Al9XdFnGGFOVKlMj7AVsUdWtqnoCWABcXcZ0jwO/\nA049vN0YU2UaNmwIQFZWFmPGjClzmsGDB3O2w9XmzJlT4hIFl112WUDOAZ45cyZPP/10pecTCJUJ\nwlbADp/HOwvHFRGRZKCNqv6rEssxxlRCy5Yteeuttyr8+tJBuGjRIpo0aRKIolUbVbazRETqALOB\nB/yYdoqIpIpIanZ2dlUVyZgaa8aMGcydO7fosbc25T2mLzk5mYSEBN59991TXpuZmUl8fDwAR48e\n5YYbbqBr166MHj2ao0ePFk131113FXXf9eijjwLwxz/+kaysLIYMGcKQIUMAaNeuHXv37gVg9uzZ\nxMfHEx8fX9R9V2ZmJl27duX2228nLi6OESNGlFhOWVavXk2fPn1ITExk9OjRHDhwoGj53i65brjh\nBgA+/fTTok5pu3fvTm5uboXe0xK8nTmWdwAuBpb6PH4IeMjncTSwF8gsHI4BWUDKmebbo0cPNaa6\nSU1NDeryV65cqQMHDix63LVrV/3uu+80Pz9fc3JyVFU1OztbO3bsqAUFBaqqGhUVpaqq27Zt07i4\nOFVVfeaZZ3Ty5MmqqrpmzRoNCwvTFStWqKrqvn37VFXV4/HooEGDdM2aNaqq2rZtW83Ozi5atvdx\namqqxsfH6+HDhzU3N1djY2N15cqVum3bNg0LC9NVq1apqurYsWP1tddeO2WdHn30Uf3973+vqqoJ\nCQn6ySefqKrqL3/5S7333ntVVfXCCy/UY8eOqarqgQMHVFX1iiuu0C+++EJVVXNzczU/P/+Ueaem\npupLL71UYrlAqp4mdypzQPUKoJOItAd2ATcAN/oEbA7QzPtYRD4BpquqnT9narYg9MPVvXt39uzZ\nQ1ZWFtnZ2cTExNCmTRvy8/N5+OGH+eyzz6hTpw67du3ihx9+oEWLFmXO57PPPmPatGkAJCYmkpiY\nWPTcwoULeeGFF/B4POzevZt169aVeL60L774gtGjRxf1fnPttdfy+eefc9VVV9G+fXu6desGlOzC\nqyw5OTkcPHiQQYMGAXDLLbcwduzYojJOmDCBa665pqhLrn79+nH//fczYcIErr32Wlq3bn3aefur\nwpvGquoB7gGWAuuBhaqaISKzROSqSpfMGFPC2LFjeeutt3jzzTcZN24cAPPnzyc7O5u0tDRWr15d\ndAW38tq2bRtPP/00H330Eenp6Vx++eUVmo+Xt/suqFwXXv/617+4++67WblyJT179sTj8TBjxgxe\nfPFFjh49Sr9+/diwYUOFy+lVqVPsVHURsKjUuF+dZtrBlVmWMdVGkPrhGjduHLfffjt79+7l008/\nBVxt6vzzz6du3bosW7aM7du3n3EeAwcO5PXXX2fo0KF88803pKenA677rqioKKKjo/nhhx9YvHgx\ngwcPBqBRo0bk5uYWdazqNWDAACZNmsSMGTNQVd555x1ee+21cq9XdHQ0MTExfP755wwYMIDXXnuN\nQYMGUVBQwI4dOxgyZAj9+/dnwYIFHD58mH379pGQkEBCQgIrVqxgw4YNdOnSpdzL9WXnGhtTQ8TF\nxZGbm0urVq248MILAZgwYQJXXnklCQkJpKSknDUQ7rrrLiZPnkzXrl3p2rVrUY86SUlJdO/enS5d\nutCmTZsS3XdNmTKFkSNH0rJlS5YtW1Y0Pjk5mUmTJtGrVy8AbrvtNrp3737GzeDTeeWVV7jzzjvJ\ny8ujQ4cOzJs3j5MnTzJx4kRycnJQVaZNm0aTJk345S9/ybJly6hTpw5xcXFFPW1XhnXDZYwfrBuu\nmqW83XDZucbGmJBnQWiMCXkWhMaYkGdBaIyfCgoKgl0E44eKfE4WhMb4ITIykh9++MHCsJorKCjg\n+++/Jz8/v1yvs8NnjPFDx44d2bJlC7t27UJEgl0ccwb5+fl89913nDx5krp16/r1GgtCY/wQERFB\nbGwsixcvZsOGDURFRVkgVmOqyuHDh+nZs6df01sQGlMOw4cPJzo6mqysLKrbMbimWHh4OH369CEh\nIcG/6au4PMbUKuHh4fTt2zfYxTABZjtLjDEhz4LQGBPyLAiNMSHPgtAYE/IsCI0xIc+C0BgT8iwI\njTEhz4LQGBPyLAiNMSHPgtAYE/IsCI0xIc+C0BgT8iwIjTEhz4LQGBPyLAiNMSGvUkEoIiNFZKOI\nbBGRGWU8f6eIrBWR1SLyhYjEVmZ5xhhTFSochCISBswFRgGxwPgygu51VU1Q1W7AU8DsCpfUGGOq\nSGVqhL2ALaq6VVVPAAuAq30nUNVDPg+jAOvb3BhT7VSmq/5WwA6fxzuB3qUnEpG7gfuBCGBoJZZn\njDFVosp3lqjqXFXtCDwIPFLWNCIyRURSRSQ1Ozu7qotkjDElVCYIdwFtfB63Lhx3OguAa8p6QlVf\nUNUUVU1p3rx5JYpkjDHlV5kgXAF0EpH2IhIB3AC85zuBiHTyeXg5sLkSyzPGmCpR4TZCVfWIyD3A\nUiAMeFlVM0RkFpCqqu8B94jIJUA+cAC4JRCFNsaYQKrUdY1VdRGwqNS4X/ncv7cy8zfGmHPBziwx\nxoQ8C0JjTMizIDTGhDwLQmNMyLMgLKcjR2Dv3mCXwhgTSJXaa1yb5eXBhg3wzTeQkVE8ZGa659u3\nh7594eKL3ZCYCOH2blYLJ07AgQOwbx/s31/20LgxxMZC167QpQs0ahTsUgfGgQOwcaNb97ZtoUMH\niIwMdqmqv5D/6R475gLPN+wyMmDrVtDCLiIiIqBzZ+jTB269FerXh6+/hmXLYP58N01kJPTq5UKx\nb183bbNmwVuv2uDYseLgOlOolR4OHz79POvUgZgYOHQI8vOLx7duXRyMXbsW36+On+Hx4+77uXGj\nGzZtKr5f1tZKy5bQsWPZQ9OmIHLu16G6EdXq1SFMSkqKpqamBny+x4+7L0xGRsla3rffQkGBmyY8\n3AVeXFzJ4cc/Lru2pwo7dsCXX8JXX7lh1SrweNzzF11UXGPs29f9uMLCAr5qlebxwM6dsG2b+4Ht\n2OFCQvXcDYcOnRpoR4+evszh4XDeee6HXJ6hcWMXhvn57rNfv754WLfO/Snm5RUvp1mzksHoHVq3\nrtoAUYWsrJIh572/bVvxdxbgggvc97ZzZ/ed69zZvTeZmW4dfYfdu0suJzraBeKPf3xqSLZq5d6r\n2kJE0lQ1pcznalsQ5ucXB57vsHkznDzppgkLg06dTg28Tp1c7a8y8vIgLa04HL/8Erz9SDRq5GqK\n3nDs0weaNKnc8vyh6oJl69bisPPebt0K331XHN5eYWHuh36uhsaN/Q+z886DqKiqCaKCAvdH4A1G\n35A8cKB4ukaN3CZ16Rpk+/blayLJzS0OON/bTZtK1mwbNCgOOd/Au+giF2b+ystzn7lvOG7Z4m63\nby/5PahXz62PNxh9w7JdO/d8RZw86dYtN7f49nT3zzTu17+GsWP9X26tDsIlS2D58uJa3qZNxR9m\nnTruwysdeBddVPEPsbxU3RfPG4pffQXp6cX/6LGxJdsaO3eu2L/wsWOuBuANt9KBl5tbcvpmzVz7\nUfv2p962aQN161Z61WsVVdiz59Qa5Pr1rubmFRHhvl+la5CRkWVvyvrW0ERcwPgGnff+uaideTzu\nT7F0LdI7HDlSsqxt2hQHY5s2bqvLnwA7U02/tKgoaNjQ/fE0alR8v2FDmDIFhg3zf161OgiHD4eP\nPnI/4tKB16WLa8+rbnJzYcWKkpvU3tpGTExxrbFvX9fu2KiRC86srLJDbtu2kj9GcOt9uqBr3772\n7ByoDnJy3CZ16Rrktm3F7cy+mjY9tWbXubMLlOr4fYXiPwLfGqTvkJ3tgrqs0CodYP6Ma9TI/XkE\nsimpVgfhrl0uPGrynrGCAldL8K01rlvnvnx16rh/29273d5QL+8/cllB16GDazeyRvDgOnrUfa7r\n17sau2/7XW1z4oTbiqjO37laHYS11cGDbs/0V1+59s3WrUuGXdu2lW/PNCaUnCkIQ/7wmeqqSRO4\n9FI3GGOqVi3aOW6MMRVjQWiMCXkWhMaYkGdBaIwJedVur7GIZAPby/myZkBt7hOmtq8f1P51tPUL\nvraqWuZlMqtdEFaEiKSebrd4bVDb1w9q/zra+lVvtmlsjAl5FoTGmJBXW4LwhWAXoIrV9vWD2r+O\ntn7VWK1oIzTGmMqoLTVCY4ypsBofhCIyUkQ2isgWEZkR7PIEkoi0EZFlIrJORDJE5N5gl6kqiEiY\niKwSkQ+CXZaqICJNROQtEdkgIutF5OJglymQROSnhd/Pb0TkDRGppp2JnV6NDkIRCQPmAqOAWGC8\niMQGt1QB5QEeUNVYoA9wdy1bP697gfXBLkQVehZYoqpdgCRq0bqKSCtgGpCiqvFAGHBDcEtVfjU6\nCIFewBZV3aqqJ4AFwNVBLlPAqOpuVV1ZeD8X9wNqFdxSBZaItAYuB14MdlmqgohEAwOBlwBU9YSq\nHgxuqQIuHGggIuFAJJB1lumrnZoehK2AHT6Pd1LLgsJLRNoB3YGvg1uSgJsD/BwoONuENVR7IBuY\nV7j5/6KIRAW7UIGiqruAp4HvgN1Ajqr+X3BLVX41PQhDgog0BN4G7lPVQ8EuT6CIyBXAHlVNC3ZZ\nqlA4kAw8r6rdgSNArWnLFpEY3FZYe6AlECUiE4NbqvKr6UG4C2jj87h14bhaQ0Tq4kJwvqr+b7DL\nE2D9gKtEJBPXrDFURP4R3CIF3E5gp6p6a/Jv4YKxtrgE2Kaq2aqaD/wv0DfIZSq3mh6EK4BOItJe\nRCJwjbTvBblMASMigmtbWq+qs4NdnkBT1YdUtbWqtsN9dh+rao2rTZyJqn4P7BCRzoWjhgHrglik\nQPsO6CMikYXf12HUwJ1BNbqrflX1iMg9wFLc3qqXVTUjyMUKpH7ATcBaEVldOO5hVV0UxDKZ8psK\nzC/8s94KTA5yeQJGVb8WkbeAlbijHFZRA88ysTNLjDEhr6ZvGhtjTKVZEBpjQp4FoTEm5FkQGmNC\nngWhMSbkWRAaY0KeBaExJuRZEBpjQl61O7OkWbNm2q5du2AXwxhTy6Slpe093XWNq10QtmvXjtTU\n1GAXwxhTy4jI9tM9Z5vGxpiQZ0FojAl5FoTGmJBX7doIjbNrFyxdCkuWQEYGdO8Offu6ISEBwsKC\nXUJT2uHDsHt3ySEry93Wrw+DB8OQIdCyZbBLakqzIKwmTpyA//zHBd+SJZCe7sa3bAlJSfDxxzB/\nvhvXsCH07g39+rlg7N0bmjQJXtnLa98+WLUKVq92t2vXggg0bQoxMe72bPcbN3avqWqqcPDgqQFX\nOuh273ZBWFpEhPsMDx6EFwsvT9W5swvEoUNdODYvcz+mOZeqXX+EKSkpGip7jTMzi4Pvo4/cD6lu\nXejfH0aNgpEjIT7e/eBV4bvvXFh++aUb1qyBggL3fFycC0VvOHbseG6C4kxUYccOF3a+ww6fy221\nbu2CPjwc9u93w4EDLiyPHz/9vMPCXCD6G5y+9yMi3Pu2b1/ZgVZ6OHbs1OVHRcGFF5YcWrY8dVxM\njPscTp50n9eyZW747DPIzXXzSkhwwThkCAwa5F5TExw6BN984/60N22C/Hz3mYO79Q6lHwdq3JQp\n7s/EXyKSpqopZT5X04MwLc2FR6dO0KBBFRYsAI4dg08/LQ6/DRvc+LZtXfCNGuV+DI0a+Te/w4dh\n+fLicPzqK8jJcc81b168Kd2vH/To4TbPqsrJk+7H4Bt4q1e7sAEXBp07u01879CtGzRrdvp5Hj3q\nQtE3IP25f/Bg8Q+mLFFRLmQ9nlOfi44+c7B5x/v7GZ2Ox+O+ux9/7ILxiy/c+oq492boUPddGDCg\n8suqrJMnYetWF3hr1rjb9HTYtq14mshIqFev+M9XpORQFeN+/WsYO9b/9ajVQThokPt3FXGB0rmz\nG7p0Kb7fsmVwakeqsGULLF7sgu+TT9yXvV49t0nkrfVddFFgyldQAOvXF9cY//Mf2LzZPVe3rgtD\nbzj27et+1BVx7JirCfiGXno65OW55yMiXC3HN/QSE10AnQsnT7o/hNOF5f797jMoHW4tWrgfdDAc\nP+7+1LzB+NVXrrkkLAx69iwOxr59q7aMBw64pgrf0Pvmm+LPtk4d931NTHQ1+cREN7RpE/wtkLOp\n1UH4zTdu2LjRDRs2uJrJkVnX738AAB1dSURBVCPF0zRsWByKviHZqVPgv1RHjrgvsjf8tm514y+6\nyIXeqFEwcOC5+8FlZ7sflTccV6wo3tRr375kMJa1EyYnp7gtzzusX19cm2rc2NXsfEOva1cXvKbi\njh51n9eyZS4cV6xw73lEBPTpU9zG2Lu3C/Xy8njcn2TpWp5vs0XTpi7sfAMvNrb6b3mdTq0OwrKo\nur2u3mD0huTGjbC91LHlvrVI35Bs1cq/fzhVWLfOhd7ixfD55+6fPCrKfVFHjYJLL4UOHSq1SgFz\n4oQLM99a4+7d7jnvTphu3Vz75apVxUEOrsbkG3jdu7swrWMHYVW53Fy3+extY1y50m0BNGjgmj68\nwdijx6l/Qnv3FgedN/QyMorbYMPD3ffeN/ASE11NubrX8soj5ILwTPLy3D+hbw3Se993r19UVMmA\n9IbkRRe5RuGPPipu6/P+i8bHF2/u9utXsX/qc03V/Tl4g/HLL92mUbt2p7bntWgR7NIar4MHXZOQ\nd1Pae5RBw4auXbFzZ1dzT08v/qMDuOCCUwOvS5ea8V2tLAtCP6i6L0xZtcjMzJKN73XquH/jxo1h\n+PDiWl/r1ue82FVCtXbVBEJBdrbbEecNxm3b3Gasb+AlJLggDFUWhJV09Kjb6eENxhMnXAD27m1t\nYaZ6sj+zU50pCO2Aaj80aOD+TRMSgl0SY/xjIVg+1sxtjAl5FoTGmJBnQWiMCXkWhMaYkOdXEIrI\nSBHZKCJbRGRGGc+3FZGPRCRdRD4RkdY+z90iIpsLh1sCWXhjjAmEswahiIQBc4FRQCwwXkRiS032\nNPCqqiYCs4DfFr62KfAo0BvoBTwqIjWkbw1jTKjwp0bYC9iiqltV9QSwALi61DSxwMeF95f5PH8p\n8G9V3a+qB4B/AyMrX2xjjAkcf4KwFeBzKjY7C8f5WgNcW3h/NNBIRM7z87XGGBNUgdpZMh0YJCKr\ngEHALuCkvy8WkSkikioiqdnZ2QEqkjHG+MefINwFtPF53LpwXBFVzVLVa1W1O/CLwnEH/Xlt4bQv\nqGqKqqY0t37LjTHnmD9BuALoJCLtRSQCuAF4z3cCEWkmIt55PQS8XHh/KTBCRGIKd5KMKBxnjDHV\nxlmDUFU9wD24AFsPLFTVDBGZJSJXFU42GNgoIpuAC4AnCl+7H3gcF6YrgFmF44wxptqw3meMMSHh\nTL3P2JklxpiQZ0FojAl5FoTGmJBnQWiMCXkWhMaYkGdBaIwJeRaExpiQZ0FojAl5FoTGmJBnQWiM\nCXkWhMaYkGdBaIwJeRaExpiQZ0FojAl5FoTGmJBnQWiMCXkWhMaYkBce7AIYUxknTpzg22+/JS8v\nL9hFMdVEZGQkHTt2JCIiwu/XWBCaGu3bb7+lSZMmdO7cmTp1bAMn1BUUFLB7925SU1PJy8tj8ODB\nhIefPebsm2NqtLy8PC644AILQQNAnTp1uPDCC6lXrx5r167lq6++8u91/kwkIiNFZKOIbBGRGWU8\n/yMRWSYiq0QkXUQuKxxfV0ReEZG1IrJeRB4q11oZ4wcLQePL+31o3LgxO3bs8O81Z5tARMKAucAo\nIBYYLyKxpSZ7BHeZz+646x7/uXD8WKCeqiYAPYA7RKSdXyUzpgbYt28f3bp1o1u3brRo0YJWrVoV\nPT5x4oRf85g8eTIbN2484zRz585l/vz5gShyyBARCgoK/JrWnzbCXsAWVd1aOPMFwNXAOp9pFGhc\neD8ayPIZHyUi4UAD4ARwyK+SGVMDnHfeeaxevRqAmTNn0rBhQ6ZPn15iGlVFVU9bc503b95Zl3P3\n3XdXvrDnmMfj8at9rjrwZ5uiFeBbv9xZOM7XTGCiiOwEFgFTC8e/BRwBdgPfAU+XdYF3EZkiIqki\nkpqdnV2+NTCmGtqyZQuxsbFMmDCBuLg4du/ezZQpU0hJSSEuLo5Zs2YVTdu/f39Wr16Nx+OhSZMm\nzJgxg6SkJC6++GL27NkDwCOPPMKcOXOKpp8xYwa9evWic+fOfPnllwAcOXKE6667jtjYWMaMGUNK\nSkpRSPt69NFH6dmzJ/Hx8dx55514r22+adMmhg4dSlJSEsnJyWRmZgLwm9/8hoSEBJKSkvjFL35R\noswA33//PT/+8Y8BePHFF7nmmmsYMmQIl156KYcOHWLo0KEkJyeTmJjIBx98UFSOefPmkZiYSFJS\nEpMnTyYnJ4cOHTrg8XgAOHDgQInHVSlQcT0e+LuqPiMiFwOviUg8rjZ5EmgJxACfi8iH3tqll6q+\nALwA7gLvASqTCTH33Qdl/O4rpVs3KMyfctuwYQOvvvoqKSnumuJPPvkkTZs2xePxMGTIEMaMGUNs\nbMlWppycHAYNGsSTTz7J/fffz8svv8yMGac0y6OqLF++nPfee49Zs2axZMkSnnvuOVq0aMHbb7/N\nmjVrSE5OLrNc9957L4899hiqyo033siSJUsYNWoU48ePZ+bMmVx55ZUcO3aMgoIC3n//fRYvXszy\n5ctp0KAB+/efUo85xapVq1i9ejUxMTHk5+fzz3/+k8aNG7Nnzx769evHFVdcwZo1a/jd737Hl19+\nSdOmTdm/fz/R0dH069ePJUuWcMUVV/DGG28wduzYc1Kr9KdGuAto4/O4deE4X7cCCwFU9SugPtAM\nuBFYoqr5qroH+A9Q5pXmjaltOnbsWBSCAG+88QbJyckkJyezfv161q1bd8prGjRowKhRowDo0aNH\nUa2stGuvvfaUab744gtuuOEGAJKSkoiLiyvztR999BG9evUiKSmJTz/9lIyMDA4cOMDevXu58sor\nAahfvz6RkZF8+OGH/OQnP6FBgwYANG3a9KzrPWLECGJiYgAX2DNmzCAxMZERI0awY8cO9u7dy8cf\nf8y4ceOK5ue9ve2224qaCubNm8fkyZPPurxA8CdqVwCdRKQ9LgBvwAWcr++AYcDfRaQrLgizC8cP\nxdUQo4A+QAX/X405s4rW3KpKVFRU0f3Nmzfz7LPPsnz5cpo0acLEiRM5duzYKa/xPQg4LCzstJuF\n9erVO+s0ZcnLy+Oee+5h5cqVtGrVikceeaTMcpxNeHh40Y6I0q/3Xe9XX32VnJwcVq5cSXh4OK1b\ntz7j8gYNGsQ999zDsmXLqFu3Ll26dCl32SrirDVCVfUA9wBLgfW4vcMZIjJLRK4qnOwB4HYRWQO8\nAUxS1/AwF2goIhm4QJ2nqulVsSLGVGeHDh2iUaNGNG7cmN27d7N06dKAL6Nfv34sXLgQgLVr15ZZ\n4zx69Ch16tShWbNm5Obm8vbbbwMQExND8+bNef/99wEXbnl5eQwfPpyXX36Zo0ePAhRtGrdr1460\ntDQA3nrrrdOWKScnh/PPP5/w8HD+/e9/s2uX25gcOnQob775ZtH8fDe5J06cyIQJE85ZbRD8bCNU\n1UW4nSC+437lc38d0K+M1x3GHUJjTEhLTk4mNjaWLl260LZtW/r1O+XnUmlTp07l5ptvJjY2tmiI\njo4uMc15553HLbfcQmxsLBdeeCG9e/cuem7+/Pnccccd/OIXvyAiIoK33367qD0vJSWFunXrcuWV\nV/L444/zs5/9jHHjxvH8888XbcqX5aabbuLKK68kISGBXr160alTJ8Btuv/85z9n4MCBhIeH06NH\nD1566SUAJkyYwKxZsxg3blzA36PTEe8eo+oiJSVFU1NTg10MU0OkpaXRo0ePYBejWvB4PHg8HurX\nr8/mzZsZMWIEmzdvrjGHsHgtWLCApUuX+nVY0emkpaWxZs0aIiIimDhxIgAikqaqZe6jqFnvkDHm\ntA4fPsywYcPweDyoKn/9619rXAjeddddfPjhhyxZsuScLrdmvUvGmNNq0qRJUbtdTfX8888HZbl2\nkqYxJuRZEBpjQp4FoTEm5FkQGmNCngWhMZUwZMiQUw6OnjNnDnfdddcZX9ewYUMAsrKyGDNmTJnT\nDB48mLMdSjZnzpwSlym47LLLOHjwoD9FNz4sCI2phPHjx7NgwYIS4xYsWMD48eP9en3Lli3PeGbG\n2ZQOwkWLFtGkSZMKz+9cU1W/+wysShaExlTCmDFj+Ne//lXUCWtmZiZZWVkMGDCg6Li+5ORkEhIS\nePfdd095fWZmJvHx8YA7/e2GG26ga9eujB49uui0NnDH13m78Hr00UcB+OMf/0hWVhZDhgxhyJAh\ngDv1be/evQDMnj2b+Ph44uPji7rwyszMpGvXrtx+++3ExcUxYsSIEsvxev/99+nduzfdu3fnkksu\n4YcffgDcsYqTJ08mISGBxMTEolP0lixZQnJyMklJSQwbNgxw/TM+/fTTRfOMj48nMzOTzMxMOnfu\nzM0330x8fDw7duwoc/0AVqxYQd++fUlKSqJXr17k5uYycODAEt2L9e/fnzVr1pTrcyvNjiM0tUcQ\n+uFq2rQpvXr1YvHixVx99dUsWLCA66+/HhGhfv36vPPOOzRu3Ji9e/fSp08frrrqKkSkzHk9//zz\nREZGsn79etLT00t0o/XEE0/QtGlTTp48ybBhw0hPT2fatGnMnj2bZcuW0axZsxLzSktLY968eXz9\n9deoKr1792bQoEHExMSwefNm3njjDf72t79x/fXX8/bbbxedfeHVv39//vvf/yIivPjiizz11FM8\n88wzPP7440RHR7N27VrA9RmYnZ3N7bffzmeffUb79u396qpr8+bNvPLKK/Tp0+e069elSxfGjRvH\nm2++Sc+ePTl06BANGjTg1ltv5e9//ztz5sxh06ZNHDt2jKSkpLMu80ysRmhMJfluHvtuFqsqDz/8\nMImJiVxyySXs2rWrqGZVls8++6wokBITE0lMTCx6buHChSQnJ9O9e3cyMjLK7FDB1xdffMHo0aOJ\nioqiYcOGXHvttXz++ecAtG/fnm7dugGn7+pr586dXHrppSQkJPD73/+ejIwMAD788MMSvWXHxMTw\n3//+l4EDB9K+fXvAv6662rZtWxSCp1u/jRs3cuGFF9KzZ0/AXYMkPDycsWPH8sEHH5Cfn8/LL7/M\npEmTzrq8s7Eaoak9gtQP19VXX81Pf/pTVq5cSV5eXtG5z/Pnzyc7O5u0tDTq1q1Lu3btKtTl1bZt\n23j66adZsWIFMTExTJo0qULz8fJ24QWuG6+yNo2nTp3K/fffz1VXXcUnn3zCzJkzy70c3666oGR3\nXb5ddZV3/SIjIxk+fDjvvvsuCxcuDMjZNFYjNKaSGjZsyJAhQ/jJT35SYieJtwuqunXrsmzZMrZv\n337G+QwcOJDXX38dgG+++Yb0dNdj3aFDh4iKiiI6OpoffviBxYsXF72mUaNG5ObmnjKvAQMG8M9/\n/pO8vDyOHDnCO++8w4ABA/xep5ycHFq1clfkeOWVV4rGDx8+nLlz5xY9PnDgAH369OGzzz5j27Zt\nQMmuulauXAnAypUri54v7XTr17lzZ3bv3s2KFSsAyM3NLep78bbbbmPatGn07NmzqBPYyrAgNCYA\nxo8fz5o1a0oE4YQJE0hNTSUhIYFXX331rJ2M3nXXXRw+fJiuXbvyq1/9qqhmmZSURPfu3enSpQs3\n3nhjiS68pkyZwsiRI4t2lnglJyczadIkevXqRe/evbntttvo3r273+szc+ZMxo4dS48ePUq0Pz7y\nyCMcOHCA+Ph4kpKSWLZsGc2bN+eFF17g2muvJSkpqaj7rOuuu479+/cTFxfHn/70Jy666KIyl3W6\n9YuIiODNN99k6tSpJCUlMXz48KKaYo8ePWjcuHHA+iy0brhMjWbdcIWmrKwsBg8ezIYNG8q8OmB5\nu+GyGqExpkZ59dVX6d27N0888cRpL5FaXrazxBhTo9x8883cfPPNAZ2n1QiNMSHPryAUkZEislFE\ntojIKRdZFZEficgyEVklIukicpnPc4ki8pWIZIjIWhGpH8gVMKY6nKJlqo+KfB/OGoQiEoa7Gt0o\nIBYYLyKxpSZ7BHd1u+64y33+ufC14cA/gDtVNQ4YDOSXu5TGnEZkZCTff/+9haEBXAh+//335Ofn\no6p+tyH600bYC9iiqlsBRGQBcDXge2i7Ao0L70cDWYX3RwDpqroGQFX3+VUqY/zUsWNH1q5dS1ZW\n1mlPXTOhJT8/n8zMTA4dOkTHjh39eo0/QdgK2OHzeCfQu9Q0M4H/E5GpQBRwSeH4iwAVkaVAc2CB\nqj7lV8mM8UNERASJiYl89NFHbNq0yWqGBoA6depw0UUX+X3Z1EDtNR4P/F1VnxGRi4HXRCS+cP79\ngZ5AHvBR4bE8H/m+WESmAFMAfvSjHwWoSCZU1K1bl5EjRzJixAiq23GxJjhEpFyH1vgThLuANj6P\nWxeO83UrMBJAVb8q3CHSDFd7/ExV9xYWbhGQDJQIQlV9AXgB3AHVfpfeGB+BOqbMhB5/vjkrgE4i\n0l5EInA7Q94rNc13wDAAEekK1AeygaVAgohEFu44GUTJtkVjjAm6s9YIVdUjIvfgQi0MeFlVM0Rk\nFpCqqu8BDwB/E5Gf4nacTFK3jXJARGbjwlSBRar6r6paGWOMqQg719gYExLsXGNjjDkDC0JjTMiz\nIDTGhDwLQmNMyLMgNMaEPAtCY0zIsyA0xoQ866HaGFMxJ07Al1/C0qWQlgZt20JcnBtiY6FlS6gh\nPQJZEBpj/KMKW7a44Fu6FJYtgyNHIDwc4uNh5Up48cXi6aOji0OxmgekBaEx5vQOHYKPPy4OP++1\niTt2hFtugREjYMgQaFzYHemePZCRAevWuduMDHjnnWofkHaKXXWTnQ1r1xYP6emwfTs0agQxMWce\nmjQp+Tg6GqxHFlMeBQVuM3fpUvi//4OvvgKPBxo2hKFD4dJL3eBnh6dFygrIjAzY59NXcxUH5JlO\nsav5Qfib38CuXdChA7Rv74YOHdybWp3l5bkvhW/orV0LP/xQPE3z5pCQ4NbnyBE4cODUweM5/TJE\n3PtwtsAs6/n69SEiAurWrXabMSbAsrJc6C1dCv/+d3E49ejhanyXXgoXX+y+D4G2Z0/JcPTe37u3\neJoABWTtDsKJE+GDDyAnp+T4mJhTw9F727Zt1XyoZTl5ErZuPTXwtmxx/77gQicuzoVeYqK7TUiA\nCy4487xVXUAePFh2SB44cObnjh/3bx0iItxQr17x/dKPz/Tc2aZt0ABGjTr7+prAOHYMPv+8OPzW\nrnXjW7QoDr7hw90fcbBkZ58ajqUD8rnn4J57/J5l7Q5CrwMHXPvF1q3u1vd+Zqbbw+UlAq1alQxH\n38Bs0aJim5R79rhNWd/Ay8iAo0eLl/vjHxcHnXfo2BHCwsq/vMo6duz04Xn8uHvPvLfewfdxRe+X\npWlT98UeP7721UAPHID16yEqym1iNmzo7kdGnpumC1XYsKG4ne/TT913MiIC+vcv3txNTKz+771v\nQA4dCl27+v3S0AjCMykocNV/33D0DcxdpTrcrlevOBjLCsq6dd0HUbqWt2dP8TzOP79k2CUmuup8\nZGRg162mUXWb874BuXMnTJ0K//0vXHMNPP+8+zOq6VTh73+H6dNh//6yp4mKKg7I0kFZ0fsNGrgt\npA8/LK717Si87FDnzsXBN2iQe12IsCA8m2PH3A6JsmqTW7eeutntKzKyeLPWdzj//HNX/trg5EmY\nPRt++Uv34/zTn+CGG6p/DeV0Nm6EO+5wta9+/eBnP3N/AEeOwOHDbvDeL2tc6fverQp/ibggjo6G\nYcOKw69t26pZ3xrAgrCySm92HztWHH4dOgRns7a2Wr8eJk+Gr792tcO//KVmtR0ePw5PPul24kVG\nwlNPwa23Vn4T+ORJt4PtbKHpva1b1x3W0ru3O87PWBCaGubkSXjmGfjVr2pW7fDTT10tcONG19b5\nhz/UrBCv5ayHalOzhIXBz38Oq1a5nUs33gjXXVfy0KLqZP9+V+sbPNi1eS5eDK+/biFYg/gVhCIy\nUkQ2isgWEZlRxvM/EpFlIrJKRNJF5LIynj8sItMDVXATArp2hf/8B373O1i0yDVHLFjg2r6qA1X4\nxz+gSxd45RV48EH45hsYOTLYJTPldNYgFJEwYC4wCogFxotIbKnJHgEWqmp33OU+/1zq+dnA4soX\n14Sc8HBXO1y50h1mNH48jBkT/Nrhli3umLubbnLlWrnStQ2G+lEBNZQ/NcJewBZV3aqqJ4AFwNWl\nplGg8GRDooEs7xMicg2wDciofHFNyIqNdbXDJ590B9DHxcGbb5772uGJE/DEE66TgeXL4c9/duVK\nTDy35TAB5U8QtgJ2+DzeWTjO10xgoojsBBYBUwFEpCHwIPBYpUtqTHi42/xctcrVwm64wdUOfY/f\nrEr/+Q8kJ8Mjj8BVV7k93HfdZedz1wKB+gTHA39X1dbAZcBrIlIHF5B/UNXDZ3qxiEwRkVQRSc3O\nzg5QkUytVbp2GBtbtbXDAwfc3uD+/SE3F95/HxYudOe6mlrBnyDcBbTxedy6cJyvW4GFAKr6FVAf\naAb0Bp4SkUzgPuBhETnl5EBVfUFVU1Q1pXkwz280NYdv7bBDB1c7HDs2sLVDVRewXbu6bqQeeMCd\nUXTFFYFbhqkW/AnCFUAnEWkvIhG4nSHvlZrmO2AYgIh0xQVhtqoOUNV2qtoOmAP8RlX/FLDSGxMb\n63pJ/u1vXU0tLs7V1ipr2za47DIXsG3aQGoqPP20O4XN1DpnDUJV9QD3AEuB9bi9wxkiMktEriqc\n7AHgdhFZA7wBTNLqdqS2qb3Cw2HGDLfntl07GDeu4rXD/Hx3NkhcHHzxBTz7rDsHunv3gBfbVB92\nZompXTwe+P3vYeZM12vyn//sQtEfX38NU6a4HoSuucb1htO6dZUW15w7dmaJCR3h4fDQQ8W1w+uv\nd0F4pp1wOTmuX7uLL3adkr7zjhssBEOGBaGpneLiXDfzv/kNvPeea0v8n/8pOY0qvP22e+7Pf3Zd\nga1f72qDJqRYEJray1s7TEsrrh1ef72rHX73HVx9tTsO8fzz3Wbxs8+6a8OYkGP985jaLz7e1Q6f\nesq1HS5b5vr3U3W93EybZl1VhTirEZrQEB4ODz/s2g67dIFLLnHXwrj/fgtBYzVCE2Li492Fi4zx\nYTVCY0zIsyA0xoQ8C0JjTMizIDTGhLxqd4qdiGQD28v5smbA3iooTnVR29cPav862voFX1tVLbN7\nq2oXhBUhIqmnO4ewNqjt6we1fx1t/ao32zQ2xoQ8C0JjTMirLUH4QrALUMVq+/pB7V9HW79qrFa0\nERpjTGXUlhqhMcZUWI0PQhEZKSIbRWSLiMwIdnkCSUTaiMgyEVknIhkicm+wy1QVRCRMRFaJyAfB\nLktVEJEmIvKWiGwQkfUicnGwyxRIIvLTwu/nNyLyhojUD3aZyqtGB6GIhAFzgVFALDBeRGKDW6qA\n8gAPqGos0Ae4u5atn9e9uOvh1FbPAktUtQuQRC1aVxFpBUwDUlQ1HgjDXeCtRqnRQQj0Arao6lZV\nPQEsAK4OcpkCRlV3q+rKwvu5uB9Qq+CWKrBEpDVwOfBisMtSFUQkGhgIvASgqidU9WBwSxVw4UAD\nEQkHIoGsIJen3Gp6ELYCdvg83kktCwovEWkHdAe+Dm5JAm4O8HOgINgFqSLtgWxgXuHm/4siEhXs\nQgWKqu4CnsZd0nc3kKOq/xfcUpVfTQ/CkCAiDYG3gftU9VCwyxMoInIFsEdV04JdlioUDiQDz6tq\nd+AIUGvaskUkBrcV1h5oCUSJyMTglqr8anoQ7gLa+DxuXTiu1hCRurgQnK+q/xvs8gRYP+AqEcnE\nNWsMFZF/BLdIAbcT2Kmq3pr8W7hgrC0uAbaparaq5gP/C/QNcpnKraYH4Qqgk4i0F5EIXCPte0Eu\nU8CIiODaltar6uxglyfQVPUhVW2tqu1wn93HqlrjahNnoqrfAztEpHPhqGHAuiAWKdC+A/qISGTh\n93UYNXBnUI3uql9VPSJyD7AUt7fqZVXNCHKxAqkfcBOwVkRWF457WFUXBbFMpvymAvML/6y3ApOD\nXJ6AUdWvReQtYCXuKIdV1MCzTOzMEmNMyKvpm8bGGFNpFoTGmJBnQWiMCXkWhMaYkGdBaIwJeRaE\nxpiQZ0FojAl5FoTGmJD3/wFZt8ni2EigKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation for last 10 epochs \n",
    "fig, ax = plt.subplots(2,1, figsize=(5, 5))\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AG9ZjTILVgJ_"
   },
   "outputs": [],
   "source": [
    "model.save_weights('cifar10_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6b7HfHHODm5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
